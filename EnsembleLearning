import numpy as np
import pandas as pd
import cv2
import os
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import VotingRegressor
import PyQt5.sip
import sys
from PIL import Image

from PyQt5.QtGui import QPixmap, QImage, QPen, QColor, QKeySequence
from PyQt5.QtCore import Qt, QEvent, QRectF, QThread, pyqtSignal, QMutex, QMutexLocker
from PyQt5.QtWidgets import QApplication, QFileDialog

# Load your image data (density maps) and corresponding labels (cell counts)
# Assuming the data is already processed and ready to be loaded as numpy arrays
# Define paths to the folders containing image data and ground truth data

app = QApplication(sys.argv)
image_groundtruth_folder = QFileDialog.getExistingDirectory(
    None,
    "Select Parent Folder (containing 'images' and 'ground_truth' subfolders)",
)
if not image_groundtruth_folder:
    print("No folder selected. Exiting.")
    
image_folder = image_groundtruth_folder + '/density_maps_sigma_10/'
ground_truth_folder = image_groundtruth_folder + '/ground_truth/'

# Load image data
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        if filename.endswith('.tiff') or filename.endswith('.tif'):
            img_path = os.path.join(folder, filename)
            with Image.open(img_path) as img:
                img = img.convert('L')  # Convert to grayscale
                img = img.resize((256, 256))  # Resize the image
                img = np.array(img)  # Convert to NumPy array
                images.append(img)
        else:
            img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)
            if img is not None:
                img = cv2.resize(img, (256, 256))  # Resize to match input shape of the CNN
                images.append(img)
    return np.array(images)

# Function to pad or truncate arrays to a specific shape
def pad_or_truncate(arr, target_shape):
    rows, cols = arr.shape
    padded = np.zeros(target_shape)
    # Fill the padded array with the original data, truncated if necessary
    padded[:min(rows, target_shape[0]), :min(cols, target_shape[1])] = arr[:min(rows, target_shape[0]), :min(cols, target_shape[1])]
    return padded

# Load ground truth data
def load_ground_truth_from_folder(folder, target_shape=(250, 100)):
    ground_truth = []
    for filename in os.listdir(folder):
        if filename.endswith('.csv'):
            file_path = os.path.join(folder, filename)
            # Read the CSV using pandas
            df = pd.read_csv(file_path)
            # Convert the data to a NumPy array (ignoring any non-numeric columns)
            numeric_data = df.select_dtypes(include=[np.number]).to_numpy()
            # Pad or truncate the data to the target shape
            padded_data = pad_or_truncate(numeric_data, target_shape)
            ground_truth.append(padded_data)
    return np.array(ground_truth)

# Load the data
X = load_images_from_folder(image_folder)
y = load_ground_truth_from_folder(ground_truth_folder)

# Normalize the image data
X = X.astype('float32') / 255.0
X = np.expand_dims(X, axis=-1)  # Add channel dimension for grayscale images

# X is the image data (e.g., density maps)
# y is the cell count labels extracted from CSV

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the CNN model
def create_cnn_model():
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 1)))  # Assuming grayscale images
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1))  # Output: Cell count
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Train CNN model
cnn_model = create_cnn_model()
cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Use a RandomForest and XGBoost model for regression as part of the ensemble
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
xgb_model = XGBRegressor(n_estimators=100, random_state=42)

# Train RandomForest and XGBoost models on the training data
rf_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)
xgb_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)

# Create the ensemble using Voting Regressor
ensemble_model = VotingRegressor([
    ('cnn', cnn_model),
    ('rf', rf_model),
    ('xgb', xgb_model)
])

# For the CNN model in VotingRegressor, you may need to define a custom wrapper if needed.
# sklearn expects predict to work in a specific way, you can use KerasRegressor wrapper if required.
from keras.wrappers.scikit_learn import KerasRegressor
import os

def cnn_wrapper():
    return create_cnn_model()

cnn_sklearn = KerasRegressor(build_fn=cnn_wrapper, epochs=10, batch_size=32, verbose=0)

# Retrain the ensemble with CNN and other models
ensemble_model = VotingRegressor([
    ('cnn', cnn_sklearn),
    ('rf', rf_model),
    ('xgb', xgb_model)
])

# Fit the ensemble
ensemble_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = ensemble_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

